{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhj+avwYxLfRQwniKv43oC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adore9303/Word-Sense-Disambiguation/blob/main/demo_research_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfIrkjcKc5nL",
        "outputId": "22d1cb86-f477-4222-b35a-13a145fa69fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Building wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52558 sha256=c04bba6068be3511b14e5f5ce2ec868a5f977d83545d90365e2202a908eade1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/92/4a/b172589446ba537db3bdb9a1f2204f27fe71217981c14ac368\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ]
        }
      ],
      "source": [
        "pip install nltk polyglot\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyicu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7HhUiuomyNw",
        "outputId": "68ba0d08-9ac5-4c18-d738-499a6d30558f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyicu\n",
            "  Downloading PyICU-2.12.tar.gz (260 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/260.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/260.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.0/260.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.12-cp310-cp310-linux_x86_64.whl size=1754546 sha256=a23a813ea9a188b7d0bd36d6f765fda25654cb1a5ba8448d1535a7bdc8035e88\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/60/95/66d97ac2fdc8be8e526c4254047405fe77feaf064282d1ad07\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycld2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFrui8Pynbbv",
        "outputId": "8488e663-93d7-4f01-b6de-9bdf2613c1ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904031 sha256=fca3c23bde5ccae262889ce61832163d96d5b67e16108b468e02d3b22ef4b141\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install morfessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSumjLtEn7ml",
        "outputId": "3880ab97-6222-44ab-fade-f4fcd73e200c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from polyglot.text import Text\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import PorterStemmer\n",
        "from itertools import chain\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def lesk(context_sentence, ambiguous_word, pos=None, stem=True, hyperhypo=True):\n",
        "    max_overlaps = 0\n",
        "    lesk_sense = None\n",
        "    context_sentence = word_tokenize(context_sentence)\n",
        "\n",
        "    for ss in wn.synsets(ambiguous_word):\n",
        "        if pos and ss.pos() != pos:\n",
        "            continue\n",
        "\n",
        "        lesk_dictionary = []\n",
        "        lesk_dictionary += ss.definition().split()\n",
        "        lesk_dictionary += ss.lemma_names()\n",
        "\n",
        "        if hyperhypo:\n",
        "            lesk_dictionary += list(chain(*[i.lemma_names() for i in ss.hypernyms() + ss.hyponyms()]))\n",
        "\n",
        "        if stem:\n",
        "            lesk_dictionary = [ps.stem(i) for i in lesk_dictionary]\n",
        "            context_sentence = [ps.stem(i) for i in context_sentence]\n",
        "\n",
        "        overlaps = set(lesk_dictionary).intersection(context_sentence)\n",
        "\n",
        "        if len(overlaps) > max_overlaps:\n",
        "            lesk_sense = ss\n",
        "            max_overlaps = len(overlaps)\n",
        "\n",
        "    return lesk_sense\n",
        "\n",
        "# Sample dataset containing sentences in Hindi and Bengali\n",
        "dataset = [\n",
        "    \"मैंने बड़े प्यार से उसका स्वागत किया।\",\n",
        "    \"তিনি একটি অসাধারণ কলম আছেন।\",\n",
        "    \"আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\",\n",
        "]\n",
        "\n",
        "for sentence in dataset:\n",
        "    print(\"Processing Sentence:\", sentence)\n",
        "\n",
        "    # Tokenize the sentence using polyglot\n",
        "    tokens = Text(sentence).words\n",
        "\n",
        "    for word in tokens:\n",
        "        print(\"Context:\", sentence)\n",
        "        answer = lesk(sentence, word)\n",
        "        print(\"Word:\", word)\n",
        "        print(\"Sense:\", answer)\n",
        "        print(\"Definition:\", answer.definition() if answer else \"No sense found\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uVfZREymbA-",
        "outputId": "a67bfdb4-39d2-4080-be14-7879b7ea8199"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Sentence: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: मैंने\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: बड़े\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: प्यार\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: से\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: उसका\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: स्वागत\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: किया\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: मैंने बड़े प्यार से उसका स्वागत किया।\n",
            "Word: ।\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Processing Sentence: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: তিনি\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: একটি\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: অসাধারণ\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: কলম\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: আছেন\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: তিনি একটি অসাধারণ কলম আছেন।\n",
            "Word: ।\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Processing Sentence: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: আমার\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: কথাগুলির\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: মধ্যে\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: তার\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: অর্থ\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: বোঝা\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: মুশকিল\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n",
            "Context: আমার কথাগুলির মধ্যে তার অর্থ বোঝা মুশকিল।\n",
            "Word: ।\n",
            "Sense: None\n",
            "Definition: No sense found\n",
            "\n"
          ]
        }
      ]
    }
  ]
}